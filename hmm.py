## Implementing Hidden Markov Model using Baum-Welch algorithm
# Load the data 

# "subject_train.txt" shows which subject number did the acts in "X_train"
# ^ the rows of "subject_train" match up with the rows of "X_train"
# ^ "y_test" gives the movement of each row from 1-6. NOTE: movements of 1 person can change during experiment
# ^ 1 WALKING, 2 WALKING_UPSTAIRS, 3 WALKING_DOWNSTAIRS, 4 SITTING, 5 STANDING, 6 LAYING

 
import os
import numpy as np 
from sklearn import preprocessing
from scipy import stats
import initialize_hmm

def main():
  # load training X training and y training data 
  x,y = load_data()
  #-----------------------------------------#
	## Baum-Welch algorithm 
  ## Step 1: Initialize all Gaussian distributions with the mean and variance along the whole dataset.
  A,B,pi = init_par()
  ## Step 2: Calculate the forward and backward probabilities for all states j and times t.
  '''
  for ? :
    forward_step()
    backward_step()
    update_par()
  '''

# load the data, standardize it (get z-scaores), initialize the model parameters
# get the indices of each activity sequence 
x_train, y_train, s_train, x_test, y_test, s_test = initialize_hmm.load_data()
x_train = initialize_hmm.standardize_data(x_train)
A, B_mean, B_var, pi, averages_x, variances_x = initialize_hmm.init_par()
activity_train = initialize_hmm.segment(y_train)
activity_test  = initialize_hmm.segment(y_test)

def forward_step(x, y, A, B, pi):
	# calculate the forward probabilities
	# alpha(i,t) is the probability of seeing x_1, x_2,... x_t (observations) and being in state i at time t
	# size of alpha: K * T
  # T: is length of sequence
  # K: number of states (6) 
  # x and y should be the feature matrix and labels corresponding to one sequence (e.g. subject 1) 

  K = 6 # number of states 
  T = np.shape(x_train)[0] # length of the sequence
  alpha = np.zeros[K,T]
  
  for i in range(K):

    # compute the emission probability of the first observation using a multivariate Gaussian
    B_1 = norm.pdf() # compute the emission probability of the first observation using a multivariate Gaussian

    alpha[i,0] = pi[i],B[i,x[i]] # initialize first alpha 

    for t in range(1,T): # compute forward probability according 
      alpha[i,t] = B[i,y_t+1]
  return alpha
       
#def backward_step(x,y,A,B):


## Step 3: For each state j and time t, use the probability Lj(t) and the current observation vector Ot to update the accumulators for that state.

## Step 4: Use the final accumulator values to calculate new parameter values.

## Step 5: If the value of P = P(O/M) for this iteration is not higher than the value at the previous iteration then stop, repeat
## the above steps using the new re-estimated parameter
## values (from step 2) 

#-----------------------------------------#

def scale_prob(alpha, beta):
  for k in range(0, K):
    c  = 1/np.sum(alpha[k,:])
    c2 = 1/np.sum(alpha[k,:])
        
    for i in range(0,T):
      alpha[k,i] = alpha[k,i] * c
      beta[k,i] = beta[k,i] * c2
  return alpha, beta

def calc_emission_initial(x, K):
  mean, cov_matrix = compute_B_initial(K)
  pdf = stats.multivariate_normal.pdf(x, mean, cov_matrix)
  return pdf

pdf = calc_emission_initial(x_train[0,], 1)


def compute_B_initial(k):
  indices  = [i for i, a in enumerate(y_train) if a == k]
  x  = [x_train[j] for j in indices]  
  x = np.asarray(x)
  avg_x  = np.mean(x, axis = 0)
  var_x  = np.cov(x.T)
  return avg_x[0:14], var_x[0:14,0:14] # figure this out 

def initialize_GMM(x):
  # Use k-means on the input data to determine the initial means
  # compute covariance using clustered samples 



def create_states(i, activityIndex, x, n):
  # i is in the index of the activity sequence (400 instances in total)
  # activityIndex is the matrix generated by segment function 
  # x is the associated data set (training or testing)
  # n is the number of states per activity sequence (7 in the literature)
  
  # get the specific frames, and the length of the activity
  start_ind  = activityIndex[i, 1]
  end_ind    = activityIndex[i, 2]
  length     = end_ind - start_ind
  frame_data = x[start_ind:end_ind, :]
  
  # need to determine how many frames are in each state
  if length >= n:
    frames_per_state = length//n
    print('{} frames per state.'.format(frames_per_state))
    # segment the frame data (average the vectors?)
    states = []
    index = 0
    for j in range(0, 7):
      data = np.mean(frame_data[index:index + frames_per_state,:], axis = 0)
      states.append(data)
      index += frames_per_state
    states = np.asarray(states)
    valid = True
  else:
    print("Activity is not long enough.")
    states = []
    valid = False
  return states, valid

if __name__ == '__main__':
  main()




